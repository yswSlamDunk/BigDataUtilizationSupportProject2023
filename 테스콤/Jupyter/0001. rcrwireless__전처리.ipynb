{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "# nltk.download()\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../Data/Raw/rcrwireless.csv'\n",
    "\n",
    "df_origin = pd.read_csv(path)\n",
    "df_origin['Date'] = pd.to_datetime(df_origin['Date'])\n",
    "df_origin['Keywords'] = df_origin['Keywords'].apply(lambda x : eval(x))\n",
    "df_origin['Category'] = df_origin['Category'].apply(lambda x : eval(x))\n",
    "df_origin = df_origin[~df_origin['Text'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_origin['Title'] = df_origin['Title'].apply(lambda x : x.lower())\n",
    "df_origin['Text'] = df_origin['Text'].apply(lambda x : x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<string>, line 1)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[0;32mc:\\Users\\WESLEYQUEST\\anaconda3\\envs\\BIgDataUtilization2023\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3526\u001b[0m in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[0;32mIn[16], line 4\u001b[0m\n    df_origin['SummarizedText'] = df_origin['SummarizedText'].apply(lambda x : eval(x))\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32mc:\\Users\\WESLEYQUEST\\anaconda3\\envs\\BIgDataUtilization2023\\Lib\\site-packages\\pandas\\core\\series.py:4771\u001b[0m in \u001b[0;35mapply\u001b[0m\n    return SeriesApply(self, func, convert_dtype, args, kwargs).apply()\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32mc:\\Users\\WESLEYQUEST\\anaconda3\\envs\\BIgDataUtilization2023\\Lib\\site-packages\\pandas\\core\\apply.py:1123\u001b[0m in \u001b[0;35mapply\u001b[0m\n    return self.apply_standard()\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32mc:\\Users\\WESLEYQUEST\\anaconda3\\envs\\BIgDataUtilization2023\\Lib\\site-packages\\pandas\\core\\apply.py:1174\u001b[0m in \u001b[0;35mapply_standard\u001b[0m\n    mapped = lib.map_infer(\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32mpandas\\_libs\\lib.pyx:2924\u001b[0m in \u001b[0;35mpandas._libs.lib.map_infer\u001b[0m\n",
      "\u001b[1;36m  Cell \u001b[1;32mIn[16], line 4\u001b[1;36m in \u001b[1;35m<lambda>\u001b[1;36m\n\u001b[1;33m    df_origin['SummarizedText'] = df_origin['SummarizedText'].apply(lambda x : eval(x))\u001b[1;36m\n",
      "\u001b[1;36m  File \u001b[1;32m<string>:1\u001b[1;36m\u001b[0m\n\u001b[1;33m    thing to increase efficiency.\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# model_checkpoint = \"google/mt5-small\"\n",
    "# pipe = pipeline('summarization', model = model_checkpoint, max_length = 512, truncation = True)\n",
    "# df_origin['SummarizedText'] = df_origin['Text'].progress_apply(lambda x : pipe(x))\n",
    "df_origin['SummarizedText'] = df_origin['SummarizedText'].apply(lambda x : eval(x))\n",
    "df_origin['SummarizedText'] = df_origin['SummarizedText'].apply(lambda x : x[0]['summary_text'])\n",
    "df_origin['SummarizedText'] = df_origin['SummarizedText'].apply(lambda x : re.sub('<.*>', 'thing', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopWords(x):\n",
    "    result = []\n",
    "    x = word_tokenize(x)\n",
    "    for word in x:\n",
    "        if word not in stop_words:\n",
    "            result.append(word)\n",
    "    return ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4470/4470 [00:00<00:00, 5863.66it/s]\n",
      "100%|██████████| 4470/4470 [00:00<00:00, 6540.48it/s]\n"
     ]
    }
   ],
   "source": [
    "df_origin['Title__stop'] = df_origin['Title'].progress_apply(lambda x : stopWords(x))\n",
    "df_origin['SummarizedText__stop'] = df_origin['SummarizedText'].progress_apply(lambda x : stopWords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Date</th>\n",
       "      <th>Text</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Href</th>\n",
       "      <th>Category</th>\n",
       "      <th>SummarizedText</th>\n",
       "      <th>Title__stop</th>\n",
       "      <th>SummarizedText__stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>next g alliance, india’s bharat 6g alliance in...</td>\n",
       "      <td>Juan Pedro Tomás</td>\n",
       "      <td>2023-09-11 11:21:18-05:00</td>\n",
       "      <td>atis’ next g alliance (nga) and india’s bhara...</td>\n",
       "      <td>[6G, Featured, Networks]</td>\n",
       "      <td>https://www.rcrwireless.com/20230911/6g/nextg-...</td>\n",
       "      <td>[6G]</td>\n",
       "      <td>thing to increase efficiency.</td>\n",
       "      <td>next g alliance , india ’ bharat 6g alliance i...</td>\n",
       "      <td>thing increase efficiency .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>south korea to start project to develop future...</td>\n",
       "      <td>Juan Pedro Tomás</td>\n",
       "      <td>2023-08-24 10:28:52-05:00</td>\n",
       "      <td>the government of south korea expects to start...</td>\n",
       "      <td>[6G, Featured, Spectrum, Standards]</td>\n",
       "      <td>https://www.rcrwireless.com/20230824/6g/south-...</td>\n",
       "      <td>[6G]</td>\n",
       "      <td>thing of 6G systems</td>\n",
       "      <td>south korea start project develop future 6g te...</td>\n",
       "      <td>thing 6G systems</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title            Author  \\\n",
       "0  next g alliance, india’s bharat 6g alliance in...  Juan Pedro Tomás   \n",
       "1  south korea to start project to develop future...  Juan Pedro Tomás   \n",
       "\n",
       "                        Date  \\\n",
       "0  2023-09-11 11:21:18-05:00   \n",
       "1  2023-08-24 10:28:52-05:00   \n",
       "\n",
       "                                                Text  \\\n",
       "0   atis’ next g alliance (nga) and india’s bhara...   \n",
       "1  the government of south korea expects to start...   \n",
       "\n",
       "                              Keywords  \\\n",
       "0             [6G, Featured, Networks]   \n",
       "1  [6G, Featured, Spectrum, Standards]   \n",
       "\n",
       "                                                Href Category  \\\n",
       "0  https://www.rcrwireless.com/20230911/6g/nextg-...     [6G]   \n",
       "1  https://www.rcrwireless.com/20230824/6g/south-...     [6G]   \n",
       "\n",
       "                  SummarizedText  \\\n",
       "0  thing to increase efficiency.   \n",
       "1            thing of 6G systems   \n",
       "\n",
       "                                         Title__stop  \\\n",
       "0  next g alliance , india ’ bharat 6g alliance i...   \n",
       "1  south korea start project develop future 6g te...   \n",
       "\n",
       "          SummarizedText__stop  \n",
       "0  thing increase efficiency .  \n",
       "1             thing 6G systems  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_origin.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "lancaster_stemmer = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4470/4470 [00:00<00:00, 5459.96it/s]\n",
      "100%|██████████| 4470/4470 [00:00<00:00, 8646.82it/s]\n",
      "100%|██████████| 4470/4470 [00:01<00:00, 4184.57it/s]\n"
     ]
    }
   ],
   "source": [
    "df_origin['PreprocessedTitle'] = df_origin['Title__stop'].progress_apply(lambda x : nltk.word_tokenize(x))\n",
    "df_origin['PreprocessedTitle'] = df_origin['PreprocessedTitle'].progress_apply(lambda x : [lemmatizer.lemmatize(word) for word in x])\n",
    "df_origin['PreprocessedTitle'] = df_origin['PreprocessedTitle'].progress_apply(lambda x : [lancaster_stemmer.stem(word) for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4470 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4470/4470 [00:00<00:00, 5965.51it/s]\n",
      "100%|██████████| 4470/4470 [00:00<00:00, 20395.01it/s]\n",
      "100%|██████████| 4470/4470 [00:00<00:00, 10309.43it/s]\n"
     ]
    }
   ],
   "source": [
    "# SummarizedText를 진행함에 있어, <extra_id_0> 이런 형식의 단어들을 thing으로 변화 필요\n",
    "df_origin['PreprossedSummarizedText'] = df_origin['SummarizedText__stop'].progress_apply(lambda x : nltk.word_tokenize(x))\n",
    "df_origin['PreprossedSummarizedText'] = df_origin['PreprossedSummarizedText'].progress_apply(lambda x : [lemmatizer.lemmatize(word) for word in x])\n",
    "df_origin['PreprossedSummarizedText'] = df_origin['PreprossedSummarizedText'].progress_apply(lambda x : [lancaster_stemmer.stem(word) for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4470/4470 [00:00<00:00, 17804.12it/s]\n"
     ]
    }
   ],
   "source": [
    "df_origin['Preprocessed'] = df_origin.progress_apply(lambda x : x['PreprocessedTitle'] + x['PreprossedSummarizedText'] + x['Keywords'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_origin' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32me:\\BigDataUtilizationSupportProject2023\\테스콤\\Jupyter\\0001. rcrwireless__전처리.ipynb 셀 14\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/BigDataUtilizationSupportProject2023/%ED%85%8C%EC%8A%A4%EC%BD%A4/Jupyter/0001.%20rcrwireless__%EC%A0%84%EC%B2%98%EB%A6%AC.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df_origin\u001b[39m.\u001b[39mhead(\u001b[39m2\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_origin' is not defined"
     ]
    }
   ],
   "source": [
    "df_origin.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_origin.to_csv('../Data/Preprocessed/rcrwireless.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BigDataUtilization2023",
   "language": "python",
   "name": "bigdatautilization2023"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
